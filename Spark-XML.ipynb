{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing XML with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = 'data/ml-latest-xml'\n",
    "datasets_csv = 'data/ml-latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process XML with DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 126 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_ratings_xml = spark.read.format(\"com.databricks.spark.xml\") \\\n",
    "          .options(rowTag='rating').load(datasets + '/ratings.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+------+\n",
      "|movieId|rating| timestamp|userId|\n",
      "+-------+------+----------+------+\n",
      "|    169|   2.5|1204927694|     1|\n",
      "|   2471|   3.0|1204927438|     1|\n",
      "|  48516|   5.0|1204927435|     1|\n",
      "|   2571|   3.5|1436165433|     2|\n",
      "| 109487|   4.0|1436165496|     2|\n",
      "+-------+------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect our ratings dataframe\n",
    "df_ratings_xml.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+------+\n",
      "|movieId|rating| timestamp|userId|\n",
      "+-------+------+----------+------+\n",
      "|  48516|   5.0|1204927435|     1|\n",
      "|   2571|   3.5|1436165433|     2|\n",
      "| 109487|   4.0|1436165496|     2|\n",
      "| 112552|   5.0|1436165496|     2|\n",
      "| 112556|   4.0|1436165499|     2|\n",
      "+-------+------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show only ratings bigger than 3\n",
    "df_ratings_xml.where('rating > 3').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the ratings equal to 5\n",
    "df_ratings_xml.where('rating = 5')    \\\n",
    "    .write \\\n",
    "    .format('com.databricks.spark.xml') \\\n",
    "    .options(rowTag='rating', rootTag='ratings') \\\n",
    "    .save(datasets + '/ratings-5.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process XML with SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''DROP TABLE IF EXISTS ratings_xml''')\n",
    "spark.sql('''CREATE TABLE ratings_xml\n",
    "USING com.databricks.spark.xml\n",
    "OPTIONS (path \"''' + datasets + '''/ratings.xml\", rowTag \"rating\")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+------+\n",
      "|movieId|rating| timestamp|userId|\n",
      "+-------+------+----------+------+\n",
      "|    169|   2.5|1204927694|     1|\n",
      "|   2471|   3.0|1204927438|     1|\n",
      "|  48516|   5.0|1204927435|     1|\n",
      "|   2571|   3.5|1436165433|     2|\n",
      "| 109487|   4.0|1436165496|     2|\n",
      "+-------+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's see what we have in our table\n",
    "spark.sql('SELECT * FROM ratings_xml LIMIT 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's define table for our 5 star ratings\n",
    "# Target path must exist.\n",
    "\n",
    "spark.sql('''DROP TABLE IF EXISTS ratings_5_xml''')\n",
    "spark.sql('''CREATE TABLE ratings_5_xml\n",
    "USING com.databricks.spark.xml\n",
    "OPTIONS (path \"''' + datasets + '''/ratings-5.xml\", rowTag \"rating\")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now overwrite it\n",
    "spark.sql('''INSERT OVERWRITE TABLE ratings_5_xml SELECT * FROM ratings_xml WHERE rating = 5''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+------+\n",
      "|movieId|rating| timestamp|userId|\n",
      "+-------+------+----------+------+\n",
      "|  48516|   5.0|1204927435|     1|\n",
      "| 112552|   5.0|1436165496|     2|\n",
      "|   2431|   5.0| 920586945|     3|\n",
      "|     94|   5.0|1037740486|     4|\n",
      "|    538|   5.0|1037740474|     4|\n",
      "+-------+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And inspect our table\n",
    "spark.sql('SELECT * FROM ratings_5_xml LIMIT 5').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation \n",
    "\n",
    "This section is creating ratings.xml file from ratings.csv.\n",
    "To understand it better, please skip it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove target directory if exists.\n",
    "! rm -rf $datasets/ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    169|   2.5|1204927694|\n",
      "|     1|   2471|   3.0|1204927438|\n",
      "|     1|  48516|   5.0|1204927435|\n",
      "+------+-------+------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read the CSV file\n",
    "df_ratings = spark.read.csv(datasets_csv + '/ratings.csv', inferSchema=True, header=True)\n",
    "\n",
    "# Register the ratings CSV data as Spark SQL view\n",
    "df_ratings.createOrReplaceTempView('ratings')\n",
    "df_ratings.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%time df_ratings.write \\\n",
    "    .format('com.databricks.spark.xml') \\\n",
    "    .options(rowTag='rating', rootTag='ratings') \\\n",
    "    .save(datasets + '/ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3.46GB data/ml-latest-xml/ratings\n"
     ]
    }
   ],
   "source": [
    "# How big is our XML dataset?\n",
    "! du -h $datasets/ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
